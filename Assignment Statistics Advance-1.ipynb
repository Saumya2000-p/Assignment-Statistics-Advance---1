{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "### Assignment Statistics Advance-1 ###",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1. Explain the properties of the F-distribution. \n2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n3. What are the key assumptions required for conducting an F-test to compare the variances of two populations? \n4. What is the purpose of ANOVA, and how does it differ from a t-test? \n5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.\n6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?\n7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n8. Question: You have two sets of data representing the incomes of two different professions:\n•\tProfession A: [48, 52, 55, 60, 62]\n•\tProfession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test?\nTask: Use Python to calculate the F-statistic and p-value for the given data.\nObjective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.\n9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data:\n•\tRegion A: [160, 162, 165, 158, 164]\n•\tRegion B: [172, 175, 170, 168, 174]\n•\tRegion C: [180, 182, 179, 185, 183]\n•\tTask: Write Python code to perform the one-way ANOVA and interpret the results.\n•\tObjective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer1. Explain the properties of the F-distribution.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "The F-distribution is a continuous probability distribution that arises frequently in statistics, especially in the context of hypothesis testing and analysis of variance (ANOVA). It is used primarily to compare variances or to assess the ratio of variances between two populations. Here are the key properties of the F-distribution:\n\n1. Shape of the Distribution\n* Skewed to the right: The F-distribution is not symmetric and is positively skewed, meaning that it has a long tail to the right.\n* Non-negative: The F-distribution only takes values greater than or equal to 0 (i.e.,𝐹≥0).\n* Degrees of freedom: The shape of the F-distribution depends on two parameters, which are the degrees of freedom of the numerator and denominator.\n2. Degrees of Freedom\nThe F-distribution is defined by two sets of degrees of freedom:\n* Numerator degrees of freedom (𝑑1): This corresponds to the degrees of freedom associated with the variance estimate from the numerator.\n* Denominator degrees of freedom (𝑑2): This corresponds to the degrees of freedom associated with the variance estimate from the denominator.\n* The exact shape of the F-distribution depends on both 𝑑1 and 𝑑2. As the degrees of freedom increase, the distribution becomes more symmetric.\n3. Mean and Variance\n* Mean: The mean of the F-distribution, when both degrees of freedom are greater than 2, is given by:\nMean=𝑑2/𝑑2−2\nfor 𝑑2>2.\n* Variance: The variance of the F-distribution is:\nVariance=2𝑑22(𝑑1+𝑑1−2)/𝑑1(𝑑2−2)2(𝑑2−4)\nThis is only defined for 𝑑2>4.\n4. Probability Density Function (PDF)\nThe probability density function (PDF) of the F-distribution is given by:\n\n𝑓(𝑥;𝑑1,𝑑2)=𝑑1𝑑1/2𝑑2𝑑2/2𝑥(𝑑1/2)−1/𝐵(𝑑1/2,𝑑2/2)(1+𝑑1/𝑑2𝑥)−(𝑑1+𝑑2)/2\nwhere:\n\n* 𝐵(⋅,⋅) is the Beta function.\n* 𝑥≥0.\n5. Cumulative Distribution Function (CDF)\nThe cumulative distribution function (CDF) of the F-distribution, which gives the probability that the random variable 𝐹 is less than or equal to a certain value 𝑥, is typically computed using specialized statistical software or tables, as the integral of the PDF does not have a simple closed-form expression.\n\n6. Applications of the F-distribution\n* Variance Ratio Test: The F-distribution is commonly used in testing the equality of variances between two populations (e.g., comparing the variability in two different data sets).\n* ANOVA (Analysis of Variance): In ANOVA, the F-distribution is used to compare the ratio of variance between groups to the variance within groups. The null hypothesis in an ANOVA test is typically that all group means are equal.\n* Regression Analysis: The F-distribution can be used to test the significance of multiple predictors in a regression model.\n7. Asymptotic Properties\n* As the degrees of freedom of both the numerator (𝑑1) and denominator (𝑑2) increase, the F-distribution approaches a normal distribution. Specifically, the distribution tends to become more symmetric and bell-shaped.\n8. Critical Values\n* The critical values of the F-distribution are often used in hypothesis testing to determine whether to reject the null hypothesis. The critical value depends on the significance level (usually denoted as 𝛼), the degrees of freedom of the numerator and denominator, and the direction of the test.\n\nIn summary, the F-distribution is a fundamental tool in inferential statistics for comparing variances, performing ANOVA, and assessing the fit of statistical models. It is characterized by its right-skewed shape, its dependence on two sets of degrees of freedom, and its application in testing hypotheses about the equality of variances.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "The **F-distribution** is used primarily in statistical tests that involve comparing variances or assessing the fit of models. Key applications include:\n\n1. **ANOVA (Analysis of Variance)**: Tests whether there are significant differences between group means by comparing the variance between groups to the variance within groups.\n   \n2. **F-test for Comparing Variances**: Compares the variances of two populations to see if they are equal.\n\n3. **Multiple Regression (F-test for Overall Significance)**: Tests whether at least one predictor variable is significantly related to the dependent variable.\n\n4. **F-test for Nested Models**: Compares the fit of two regression models, one simpler (with fewer predictors) and one more complex, to determine if the additional predictors improve the model significantly.\n\n5. **General Linear Models (GLM) and ANCOVA**: Used to test hypotheses about multiple predictors in a model.\n\nThe F-distribution is appropriate for these tests because it arises from the ratio of two independent estimates of population variances, and under the null hypothesis, this ratio follows the F-distribution. It's widely used in variance comparison and model fitting tests.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer3. What are the key assumptions required for conducting an F-test to compare the variances of two populations? ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "When conducting an **F-test** to compare the variances of two populations, there are several key assumptions that must be met for the test to be valid. These assumptions ensure the reliability of the results. The key assumptions are:\n\n### 1. **Independence of Samples**\n   - The two samples being compared must be independent of each other. This means that the data in one sample should not influence or be related to the data in the other sample. For example, if you're comparing the variances of two different groups (e.g., two treatment groups), the observations in one group should not affect the observations in the other.\n\n### 2. **Normality of the Populations**\n   - Both populations from which the samples are drawn should be **normally distributed** (or approximately normal). The F-test relies on the assumption that the sample variances are estimates of the variances from normal populations. If the data are heavily skewed or non-normal, the F-test may be inaccurate, especially with small sample sizes. However, the test can be somewhat robust to violations of normality with large sample sizes due to the central limit theorem.\n\n### 3. **Random Sampling**\n   - Both samples should be **randomly selected** from their respective populations. This ensures that the samples are representative of the populations and that the results of the test can be generalized to the larger population.\n\n### 4. **Scale of Measurement**\n   - The variable being measured should be on a continuous scale (i.e., interval or ratio level). The F-test compares variances, and variances are meaningful only for continuous data.\n\n### 5. **Homogeneity of Variances (Optional but Common in Applications)**\n   - Although this is not a requirement for the F-test itself, many applications (e.g., ANOVA) assume **homogeneity of variances** between the two populations being compared. This assumption means that the two populations have the same variance, which is often tested before performing the F-test.\n\n---\n\n### **Summary of Assumptions**:\n1. **Independence**: The two samples are independent of each other.\n2. **Normality**: Both populations are normally distributed.\n3. **Random Sampling**: The samples are randomly selected.\n4. **Continuous Data**: The variable being measured is continuous.\n5. **Homogeneity of Variances** (for some tests like ANOVA): The variances of the two populations are equal (if testing for equality of variances is the ultimate goal).\n\nIf these assumptions are violated, the results of the F-test may be unreliable, and alternative methods or corrections (such as using non-parametric tests or transforming the data) may be considered.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer4. What is the purpose of ANOVA, and how does it differ from a t-test?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "### Purpose of **ANOVA (Analysis of Variance)**:\nANOVA is a statistical method used to test whether there are any statistically significant differences between the means of three or more groups. It is primarily used when you have multiple groups and want to determine if they have different population means. Instead of comparing each pair of groups individually (which can lead to an inflated Type I error rate), ANOVA provides a way to test the equality of means across all groups simultaneously.\n\n### Key Purpose:\n- **Test for significant differences**: ANOVA evaluates if at least one group mean is different from the others, based on the variation in the data.\n- **Compare multiple groups**: It's typically used when there are three or more groups to compare. For example, ANOVA might be used to compare the effectiveness of three different treatments on patient outcomes.\n\n### How **ANOVA** Works:\nANOVA tests the **null hypothesis** that all group means are equal. It does so by comparing the **variance between groups** (how much the group means deviate from the overall mean) with the **variance within groups** (how much individual data points deviate from their respective group means).\n\n- **Between-group variance**: Measures how much the means of the groups differ from the overall mean.\n- **Within-group variance**: Measures the variability of data points within each group.\n\nThe **F-statistic** is calculated as the ratio of these variances. If the F-statistic is large, it suggests that the between-group variability is greater than within-group variability, indicating that at least one group mean is significantly different.\n\n### Purpose of **t-test**:\nA **t-test** is used to compare the means of two groups to see if they are statistically significantly different from each other. There are three types of t-tests:\n1. **One-sample t-test**: Compares the mean of a sample to a known value or population mean.\n2. **Independent two-sample t-test**: Compares the means of two independent groups.\n3. **Paired sample t-test**: Compares the means of two related groups, such as before and after treatment.\n\n### Key Difference Between **ANOVA** and **t-test**:\n\n1. **Number of Groups**:\n   - **t-test**: Compares the means of **two** groups.\n   - **ANOVA**: Compares the means of **three or more** groups.\n\n2. **Null Hypothesis**:\n   - **t-test**: The null hypothesis is that the two group means are equal.\n   - **ANOVA**: The null hypothesis is that **all** group means are equal.\n\n3. **When to Use**:\n   - **t-test**: Use when comparing the means of exactly two groups.\n   - **ANOVA**: Use when comparing the means of three or more groups. It can also be extended to more complex models (e.g., factorial ANOVA).\n\n4. **Multiple Comparisons**:\n   - **t-test**: If you want to compare more than two groups, using multiple t-tests can increase the risk of Type I error (false positives) because each test adds more chances to incorrectly reject the null hypothesis.\n   - **ANOVA**: ANOVA controls for the overall Type I error rate when comparing multiple groups. If ANOVA finds significant differences, post-hoc tests (like Tukey's or Bonferroni) can be used to determine which specific groups differ from each other.\n\n5. **F-statistic vs. t-statistic**:\n   - **t-test**: The test statistic is the **t-statistic**, which is calculated as the difference between the two group means divided by the standard error.\n   - **ANOVA**: The test statistic is the **F-statistic**, which is the ratio of the variance between groups to the variance within groups.\n\n### Summary of Differences:\n\n| Feature                      | **t-test**                               | **ANOVA**                                 |\n|------------------------------|------------------------------------------|-------------------------------------------|\n| **Number of groups**          | Two                                      | Three or more                             |\n| **Null hypothesis**           | Group means are equal                    | All group means are equal                 |\n| **Purpose**                   | Compare two means                        | Compare means across multiple groups      |\n| **Risk of Type I Error**      | Increases with multiple comparisons      | Controls for Type I error with multiple groups |\n| **Test statistic**            | t-statistic                              | F-statistic                               |\n| **Post-hoc tests**            | Not applicable                           | Used if ANOVA is significant (e.g., Tukey's) |\n\n### Conclusion:\n- Use a **t-test** when comparing **two** groups.\n- Use **ANOVA** when comparing **three or more** groups. ANOVA is a more powerful and appropriate method for handling multiple comparisons, as it avoids the inflated error rate that can arise from performing multiple t-tests. If ANOVA indicates significant differences, post-hoc tests can be used to identify which specific groups differ.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "### Why Use **One-Way ANOVA** Instead of Multiple t-tests?\n\nWhen comparing **more than two groups**, it is generally better to use **one-way ANOVA** rather than conducting multiple **t-tests**. Here's why:\n\n### 1. **Control for Type I Error Rate**\n   - **Problem with Multiple t-tests**: When you perform multiple t-tests, the probability of making at least one **Type I error** (incorrectly rejecting a true null hypothesis) increases as the number of comparisons increases. This is because each t-test carries its own risk of error (usually set at a significance level of \\( \\alpha = 0.05 \\)). For example, if you conduct 5 t-tests, the overall chance of making at least one false positive is higher than 5%.\n   \n   - **Solution with One-Way ANOVA**: One-way ANOVA allows you to test the equality of means across all groups in a single test, thus **controlling the overall Type I error rate**. By testing all groups simultaneously, you reduce the risk of making a false discovery. The significance level \\( \\alpha \\) is maintained at the intended value (e.g., 0.05).\n\n### 2. **Efficiency and Simplicity**\n   - **Problem with Multiple t-tests**: If you have more than two groups (say, 4 or 5), performing all pairwise comparisons with t-tests can become cumbersome and inefficient. For example, with 4 groups, you would need 6 t-tests (since \\( \\binom{4}{2} = 6 \\)), and for 5 groups, you would need 10 tests. This increases both the computational effort and the complexity of interpreting the results.\n   \n   - **Solution with One-Way ANOVA**: One-way ANOVA is a single test that evaluates whether there are any overall differences among the means of all groups. If the ANOVA results in a significant F-statistic, you can then proceed to post-hoc tests (such as Tukey’s HSD or Bonferroni) to determine **which specific groups** differ. This is far more efficient than conducting multiple t-tests.\n\n### 3. **Statistical Power**\n   - **Problem with Multiple t-tests**: When you conduct multiple t-tests, each test is less likely to detect a true effect due to the inflation of Type I error and the lack of adjustment for multiple comparisons. In other words, performing multiple t-tests can reduce the **power** of the overall analysis (the ability to detect a true effect if one exists).\n   \n   - **Solution with One-Way ANOVA**: Since one-way ANOVA evaluates the overall differences across all groups in a single test, it maintains a higher level of statistical power compared to conducting multiple t-tests. The ANOVA method pools information from all the groups, making the test more sensitive to differences between them.\n\n### 4. **Holistic Comparison**\n   - **Problem with Multiple t-tests**: Multiple t-tests only tell you whether two specific groups are different. However, they do not provide a comprehensive view of how all the groups compare to each other simultaneously.\n   \n   - **Solution with One-Way ANOVA**: One-way ANOVA tests the overall hypothesis that **all group means are equal**, considering all groups simultaneously. If the ANOVA test is significant, you know that at least one group differs from the others, and you can then conduct post-hoc tests to explore which specific group pairs show significant differences.\n\n### When to Use One-Way ANOVA Instead of Multiple t-tests:\n\n- **When comparing more than two groups**: One-way ANOVA is the appropriate method if you have three or more groups and want to test whether there are any significant differences between their means.\n  \n- **When you want to control Type I error**: Using multiple t-tests increases the chances of false positives (Type I errors). ANOVA controls the overall error rate and reduces the risk of making an incorrect conclusion.\n\n- **When you want an overall test for equality of means**: If you’re interested in knowing whether any group differs from the others, ANOVA is the way to go because it tests the null hypothesis that all means are equal across the groups.\n\n### Key Takeaways:\n\n- **One-way ANOVA** is used when you have three or more groups and want to test if there are any overall differences between them.\n- It **controls Type I error rate** by testing all groups in a single statistical test, rather than conducting multiple t-tests.\n- **Multiple t-tests** increase the chance of Type I errors and are inefficient for comparing more than two groups.\n- If ANOVA results in a significant finding, post-hoc tests can be used to identify which specific pairs of groups differ.\n\nIn summary, one-way ANOVA is more reliable, efficient, and powerful than performing multiple t-tests when comparing more than two groups. It provides a global test for differences in means and avoids the pitfalls of inflated error rates due to multiple comparisons.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "In **ANOVA**, the total variance in the data is partitioned into two components:\n\n1. **Between-Group Variance**: This represents the variability due to differences in the group means. It shows how much the group means deviate from the overall grand mean.\n   \n2. **Within-Group Variance**: This represents the variability within each group, capturing random error or individual differences within the groups.\n\n### F-statistic Calculation:\nThe **F-statistic** is calculated as the ratio of these variances:\n\nF = [Mean Square Between (MSB)]\\[Mean Square Within (MSW)]\n\nWhere:\n- **MSB** is the average between-group variance (SSbetween/ dfbetween).\n- **MSW** is the average within-group variance (SSwithin/ dfwithin).\n\n### Interpretation:\n- A large **F-statistic** suggests that the group means are significantly different (i.e., reject the null hypothesis of equal means).\n- A small **F-statistic** suggests no significant difference between the group means (i.e., fail to reject the null hypothesis).\n\nThis partitioning allows ANOVA to test whether any group mean differs significantly from the others while controlling the error rate.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Here’s a simpler comparison of the **frequentist (classical)** approach to **ANOVA** and the **Bayesian** approach:\n\n### 1. **How They Handle Uncertainty**\n- **Frequentist**: Uncertainty is treated as random variability in the sample. We use **confidence intervals** and **p-values** to quantify how likely it is that the observed data occurred under the null hypothesis (no differences between groups).\n- **Bayesian**: Uncertainty is treated as a **probability** about the parameters themselves. We use **probability distributions** to express what we believe the parameters could be, given the data and prior knowledge.\n\n### 2. **Parameter Estimation (Finding Group Means)**\n- **Frequentist**: Estimates (like group means) are single numbers. For example, we compute the sample means for each group and use them as point estimates.\n- **Bayesian**: Estimates are **probabilistic**. Instead of just one number (like the sample mean), Bayesian methods provide a **range** of possible values for the parameter, showing the uncertainty around the estimate.\n\n### 3. **Hypothesis Testing**\n- **Frequentist**: You test a **null hypothesis** (e.g., that all group means are the same) and check the **p-value**. If the p-value is small (typically less than 0.05), you reject the null hypothesis and conclude there are significant differences between groups.\n- **Bayesian**: You compare the **probabilities** of different hypotheses (like comparing the likelihood of equal vs. different group means) using **Bayes Factors** or check the **posterior probability** of a hypothesis being true.\n\n### 4. **Prior Knowledge**\n- **Frequentist**: No prior knowledge is used; the focus is on the data you have.\n- **Bayesian**: You can **incorporate prior knowledge** about the groups or the parameters into the analysis through **prior distributions**. This is helpful when you have expert knowledge or past data.\n\n### 5. **Interpretation of Results**\n- **Frequentist**: The result is usually a p-value, which tells you if there’s evidence to reject the null hypothesis. If p < 0.05, you might say there’s a significant difference between the groups.\n- **Bayesian**: You get a **posterior distribution** that tells you the **probability** of a hypothesis (like \"are the group means equal?\"). You can also compute a **Bayes Factor** to directly compare different models (e.g., whether the means are equal or different).\n\n### Key Differences in a Table:\n\n| **Aspect**               | **Frequentist**                          | **Bayesian**                         |\n|--------------------------|------------------------------------------|--------------------------------------|\n| **Uncertainty**           | Confidence intervals, p-values           | Probability distributions, posterior  |\n| **Parameter Estimation**  | Point estimates (e.g., group means)      | Distributions of possible parameter values |\n| **Hypothesis Testing**    | p-value, null hypothesis significance    | Bayes Factors, posterior probabilities |\n| **Prior Knowledge**       | No prior knowledge used                 | Prior knowledge incorporated via priors |\n| **Result Interpretation** | p-value tells if differences are significant | Probability of hypotheses based on data |\n\n### Simple Summary:\n- **Frequentist** focuses on testing hypotheses and making decisions based on p-values (reject or fail to reject the null hypothesis).\n- **Bayesian** focuses on updating beliefs about the parameters using **probabilities** and prior knowledge, providing a more flexible and detailed view of uncertainty.\n\nIn short, **Frequentist** methods are more traditional and focus on data alone, while **Bayesian** methods combine data with prior beliefs and give a more complete picture of uncertainty and parameter estimation.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer8. Question: You have two sets of data representing the incomes of two different professions:\n•\tProfession A: [48, 52, 55, 60, 62]\n•\tProfession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions' incomes are equal. What are your conclusions based on the F-test?\nTask: Use Python to calculate the F-statistic and p-value for the given data.\nObjective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "To perform an F-test to determine if the variances of the two professions' incomes are equal, we need to follow these steps:\n\n1. State the Hypotheses:\n* Null Hypothesis (𝐻0): The variances of the two professions' incomes are equal, i.e., 𝜎𝐴2=𝜎𝐵2.\n* Alternative Hypothesis (𝐻𝑎): The variances of the two professions' incomes are not equal, i.e., 𝜎𝐴2≠𝜎𝐵2.\n2. Calculate the F-statistic: The F-statistic is calculated as the ratio of the two sample variances:\n 𝐹=𝑠𝐴2/𝑠𝐵2\n\nwhere:\n* 𝑠𝐴2 is the variance of Profession A's incomes.\n* 𝑠𝐵2 is the variance of Profession B's incomes.\n3. Determine the degrees of freedom: The degrees of freedom for each sample are:\n* 𝑑𝑓𝐴=𝑛𝐴−1(where 𝑛𝐴 is the number of observations in Profession A).\n* 𝑑𝑓𝐵=𝑛𝐵−1(where 𝑛𝐵 is the number of observations in Profession B).\n4. Calculate the p-value: Using the calculated F-statistic and degrees of freedom, we can find the p-value using the F-distribution.\n\nNow, let's perform the F-test using Python. Here’s the code to calculate the F-statistic and p-value:",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom scipy.stats import f\n\n# Data for the two professions\nprofession_A = [48, 52, 55, 60, 62]\nprofession_B = [45, 50, 55, 52, 47]\n\n# Step 1: Calculate the sample variances for both professions\nvar_A = np.var(profession_A, ddof=1)  # Sample variance, ddof=1 for unbiased estimate\nvar_B = np.var(profession_B, ddof=1)\n\n# Step 2: Calculate the F-statistic (larger variance / smaller variance)\nF_statistic = var_A / var_B if var_A > var_B else var_B / var_A\n\n# Step 3: Degrees of freedom for both samples\ndf_A = len(profession_A) - 1\ndf_B = len(profession_B) - 1\n\n# Step 4: Calculate the p-value using the F-distribution\np_value = 2 * min(f.cdf(F_statistic, df_A, df_B), 1 - f.cdf(F_statistic, df_A, df_B))\n\n# Output the results\nprint(f\"F-statistic: {F_statistic}\")\nprint(f\"p-value: {p_value}\")\n\n# Conclusion based on the p-value (assuming significance level of 0.05)\nif p_value < 0.05:\n    print(\"Reject the null hypothesis: The variances are significantly different.\")\nelse:\n    print(\"Fail to reject the null hypothesis: The variances are not significantly different.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "F-statistic: 2.089171974522293\np-value: 0.49304859900533904\nFail to reject the null hypothesis: The variances are not significantly different.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "Explanation:\n1. Variance Calculation: The variances for both professions are computed using np.var() with ddof=1, which gives the sample variance (biased estimate).\n2. F-statistic: The ratio of the larger variance to the smaller variance is calculated.\n3. Degrees of Freedom: The degrees of freedom for each profession are 𝑛𝐴−1 and 𝑛𝐵−1.\n4. p-value: The p-value is calculated using the cumulative distribution function (CDF) of the F-distribution (f.cdf()) for both tails since we are testing for differences in variances (two-tailed test).\n5. Conclusion: If the p-value is less than 0.05, we reject the null hypothesis that the variances are equal.\n\nResults:\nRunning this code will provide the F-statistic and p-value, allowing you to make a conclusion about whether the variances of the two professions' incomes are equal.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "F-Test Summary\n1. Objective: Test if the variances of two groups (Professions A and B) are equal.\n2. Hypotheses:\n* Null Hypothesis (𝐻0): The variances are equal (𝜎𝐴2=𝜎𝐵2).\n* Alternative Hypothesis (𝐻𝑎): The variances are not equal (𝜎𝐴2≠𝜎𝐵2).\n3. Steps:\n* Calculate the variances for both groups.\n* Compute the F-statistic: 𝐹=larger variance/smaller variance.\n* Degrees of freedom: 𝑑𝑓𝐴=𝑛𝐴−1, 𝑑𝑓𝐵=𝑛𝐵−1.\n* Find the p-value using the F-distribution.\n4. Conclusion:\n* If p-value < 0.05: Reject the null hypothesis (variances are significantly different).\n* If p-value ≥ 0.05: Fail to reject the null hypothesis (variances are not significantly different).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom scipy.stats import f\n\n# Data\nA = [48, 52, 55, 60, 62]\nB = [45, 50, 55, 52, 47]\n\n# Calculate sample variances\nvar_A = np.var(A, ddof=1)\nvar_B = np.var(B, ddof=1)\n\n# F-statistic\nF = var_A / var_B if var_A > var_B else var_B / var_A\n\n# Degrees of freedom\ndf_A = len(A) - 1\ndf_B = len(B) - 1\n\n# p-value\np_value = 2 * min(f.cdf(F, df_A, df_B), 1 - f.cdf(F, df_A, df_B))\n\n# Output results\nprint(f\"F-statistic: {F}, p-value: {p_value}\")\nif p_value < 0.05:\n    print(\"Reject the null hypothesis: The variances are significantly different.\")\nelse:\n    print(\"Fail to reject the null hypothesis: The variances are not significantly different.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "F-statistic: 2.089171974522293, p-value: 0.49304859900533904\nFail to reject the null hypothesis: The variances are not significantly different.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "Answer9. Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data:\n•\tRegion A: [160, 162, 165, 158, 164]\n•\tRegion B: [172, 175, 170, 168, 174]\n•\tRegion C: [180, 182, 179, 185, 183]\n•\tTask: Write Python code to perform the one-way ANOVA and interpret the results.\n•\tObjective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "To perform a one-way ANOVA to test if there are statistically significant differences in average heights between three different regions, we follow these steps:\n\n1. Hypotheses:\n* Null Hypothesis (𝐻0): The mean heights are the same across all three regions. That is, 𝜇𝐴=𝜇𝐵=𝜇𝐶.\n* Alternative Hypothesis (𝐻𝑎): At least one of the mean heights is different.\n2. F-statistic:\nThe F-statistic in a one-way ANOVA is calculated as the ratio of:\n* Between-group variance (variation due to the differences between the group means).\n* Within-group variance (variation within each group).\n3. Python Code:\nWe will use the scipy.stats library, which has an easy-to-use function for one-way ANOVA: f_oneway(). This function returns the F-statistic and p-value.\n4. Steps in Python:\n* Organize the data for each region.\n* Use scipy.stats.f_oneway() to perform the ANOVA.\n* Interpret the F-statistic and p-value.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nfrom scipy.stats import f_oneway\n\n# Data for the three regions\nregion_A = [160, 162, 165, 158, 164]\nregion_B = [172, 175, 170, 168, 174]\nregion_C = [180, 182, 179, 185, 183]\n\n# Perform one-way ANOVA\nF_statistic, p_value = f_oneway(region_A, region_B, region_C)\n\n# Output the results\nprint(f\"F-statistic: {F_statistic}\")\nprint(f\"p-value: {p_value}\")\n\n# Conclusion based on the p-value (assuming significance level of 0.05)\nif p_value < 0.05:\n    print(\"Reject the null hypothesis: There are significant differences in average heights between the regions.\")\nelse:\n    print(\"Fail to reject the null hypothesis: There are no significant differences in average heights between the regions.\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "F-statistic: 67.87330316742101\np-value: 2.870664187937026e-07\nReject the null hypothesis: There are significant differences in average heights between the regions.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "Explanation:\n1. Input Data: The data for the heights of individuals in three regions (A, B, and C) is stored in separate lists.\n2. ANOVA: We perform the one-way ANOVA using f_oneway(). This function returns the F-statistic and the p-value.\n3. Decision: Based on the p-value, we decide whether to reject the null hypothesis (indicating significant differences between the regions).\nInterpretation:\n* F-statistic: A higher F-statistic indicates a larger difference between group means relative to within-group variance.\n* p-value: The p-value helps determine whether the observed differences between the group means are statistically significant. If the p-value is less than the significance level (usually 0.05), we reject the null hypothesis.\n\nConclusion:\nIn this example, the F-statistic is quite large, and the p-value is very small (less than 0.05). Therefore, we reject the null hypothesis, meaning there are significant differences in the average heights between the three regions.\n\nKey Takeaways:\n* One-way ANOVA tests whether there are significant differences in means across more than two groups.\n* The F-statistic compares the between-group variation to the within-group variation.\n* The p-value helps decide whether to reject the null hypothesis.\n* If p-value < 0.05, it indicates that the differences between group means are statistically significant.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}